{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dubbing Pipeline with CDK\n",
    "\n",
    "After deploying the solution using CDK, you can invoke the \n",
    "pipeline by uploading a sample and job file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## The following are required parameters to set\n",
    "\n",
    "# Region and S3 parameters\n",
    "region_name = boto3.session.Session().region_name\n",
    "\n",
    "# Provide any job name, used for creating the s3 prefixes\n",
    "job_name = \"lipsync-4\"\n",
    "\n",
    "# Source\n",
    "source_file = \"./samples/aws-fr.mp4\"                     # Source video to localize\n",
    "media_format = \"mp4\"                                          # Specify the media format for Amazon Transcribe\n",
    "\n",
    "# Transcription\n",
    "transcribe_source_language_code = \"fr-CA\"                     # Amazon Transcribe language code: en-US, es-US, ...\n",
    "\n",
    "# Translation\n",
    "translate_source_language_code = \"fr-CA\"                         # Amazon Translate language codes: en, es, ...\n",
    "translate_target_language_code = \"en\"                         # Amazon Translate language codes: en, es, ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def get_bucket(s3_uri):\n",
    "    bucket = s3_uri.split(\"/\")[2]\n",
    "    return bucket\n",
    "    \n",
    "def get_key(s3_uri):\n",
    "    key = \"/\".join(s3_uri.split(\"/\")[3:])\n",
    "    return key\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the outputs of the pipeline stack\n",
    "\n",
    "cf_client = boto3.client('cloudformation', region_name=region_name)\n",
    "s3_client = boto3.client('s3',region_name=region_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve stack outputs\n",
    "sm_stack_name = \"SageMakerEndpointsStack\"\n",
    "vd_stack_name = \"VisualDubbingLipsyncCdkStack\"\n",
    "\n",
    "stacks = [sm_stack_name, vd_stack_name]\n",
    "\n",
    "stacks_output_dict = {}\n",
    "\n",
    "for stack_name in stacks:\n",
    "    # Retrieve the stack\n",
    "    print(f\"Retrieving CF stack details: {stack_name}\")\n",
    "    response = cf_client.describe_stacks(StackName=stack_name)\n",
    "\n",
    "    # Get the outputs\n",
    "    print(\"Parsing response\")\n",
    "    outputs = response['Stacks'][0]['Outputs']\n",
    "\n",
    "    # Convert the outputs to a dictionary\n",
    "    output_dict = {output['OutputKey']: output['OutputValue'] for output in outputs}\n",
    "\n",
    "    stacks_output_dict.update(output_dict)\n",
    "\n",
    "stacks_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the object keys\n",
    "\n",
    "bucket = stacks_output_dict['VDBucketOutput']\n",
    "\n",
    "input_job_key = f\"inputs/{job_name}/pipeline_job/{job_name}.json\"\n",
    "input_video_key = f\"inputs/{job_name}/videos/{source_file.split('/')[-1]}\"\n",
    "output_video_key = f\"outputs/{job_name}/{source_file.split('/')[-1]}\"\n",
    "\n",
    "print(input_job_key)\n",
    "print(input_video_key)\n",
    "print(output_video_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload the video to process\n",
    "\n",
    "s3 = boto3.client('s3', region_name=region_name)\n",
    "s3.upload_file(source_file, bucket, input_video_key)\n",
    "print(f\"Uploaded file to s3://{bucket}/{input_video_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the job file\n",
    "job = {\n",
    "    \"bucket\": bucket,\n",
    "    \"prefix_inputs\": \"inputs\",\n",
    "    \"prefix_outputs\": \"outputs\",\n",
    "    \"job_name\": job_name,\n",
    "    \"transcribe_source_language_code\": transcribe_source_language_code,\n",
    "    \"media_format\": \"mp4\",\n",
    "    \"translate_source_language_code\": translate_source_language_code,\n",
    "    \"translate_target_language_code\": translate_target_language_code,\n",
    "    \"tts_endpoint_name\": stacks_output_dict['SageMakerTTSEndpointOutput'],\n",
    "    \"tts_model_id\": \"\", #Not currently used\n",
    "    \"retalking_endpoint_name\": stacks_output_dict['SageMakerRetalkingEndpointOutput'],\n",
    "    \"source_file_s3_uri\": f\"s3://{bucket}/{input_video_key}\",\n",
    "    \"destination_s3_uri\": f\"s3://{bucket}/{output_video_key}\"\n",
    "}\n",
    "\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload the job file which will start the pipeline\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource_obj = s3_resource.Object(bucket, input_job_key)\n",
    "s3_resource_obj.put(Body=json.dumps(job).encode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Poll the destination S3 URI for completion\n",
    "\n",
    "# Poll for completion\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "all_completed = False  # Flag to track completion\n",
    "\n",
    "while not all_completed:\n",
    "    print(\"=================\")\n",
    "    print(f\"Checking progress - {datetime.now()}\")\n",
    "    completed_count = 0  # Count completed payloads\n",
    "\n",
    "    key = \"/\".join(job['destination_s3_uri'].split(\"/\")[3:])\n",
    "    try:\n",
    "        s3.head_object(Bucket=bucket, Key=key)\n",
    "        print(\" Completed.\")\n",
    "        all_completed = True\n",
    "    except:\n",
    "        print(\" In Progress.\")\n",
    "\n",
    "    if all_completed:\n",
    "        print(\"Retalking completed!\")\n",
    "    else:\n",
    "        sleep(10)\n",
    "        clear_output(wait=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download file \n",
    "bucket = get_bucket(job['destination_s3_uri'])\n",
    "key = get_key(job['destination_s3_uri'])\n",
    "\n",
    "s3.download_file(bucket, key, output_video_key.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
