{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Media Content Localization Pipeline\n",
    "This notebook will allow you to do the visual dubbing and lipsync pipeline.\n",
    "\n",
    "Prerequisites:\n",
    "- ffmpeg\n",
    "- Completed 1 - Deploy SageMaker Endpoint.ipynb\n",
    "- TTS Endpoints and Retalking Endpoints are in service\n",
    "\n",
    "The following notebook has the following sections:\n",
    "\n",
    "1. Parameters\n",
    "2. Upload file to S3 and Transcribe source file\n",
    "3. Translate using Amazon Translate\n",
    "4. Create voice samples for voice cloning\n",
    "5. Perform Text-to-speech\n",
    "6. Perform Video Retalking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json \n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "import tempfile\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Set the following parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The following are required parameters to set\n",
    "\n",
    "# Region and S3 parameters\n",
    "region_name = '<region>'\n",
    "\n",
    "bucket = \"<bucket name>\"                                      # Specify the bucket to be used\n",
    "\n",
    "# Source\n",
    "source_file = \"./samples/aws-fr.mp4\"                     # Source video to localize\n",
    "media_format = \"mp4\"                                          # Specify the media format for Amazon Transcribe\n",
    "\n",
    "# Transcription\n",
    "transcribe_source_language_code = \"fr-CA\"                     # Amazon Transcribe language code: en-US, es-US, ...\n",
    "\n",
    "# Translation\n",
    "translate_source_language_code = \"fr-CA\"                         # Amazon Translate language codes: en, es, ...\n",
    "translate_target_language_code = \"en\"                         # Amazon Translate language codes: en, es, ...\n",
    "\n",
    "# Reference voice samples creation\n",
    "s3_reference_voice_folder = \"aws-french\"                     # The folder name to store the voice samples in s3 \n",
    "voice_samples_dir = \"./voice-samples/aws-french\"             # Directory to store the reference voice clips after splitting\n",
    "\n",
    "inference_id = \"aws-french\"                                  # Give it a unique inference id is the folder to store in inputs and outputs\n",
    "\n",
    "# TTS Inference parameters \n",
    "endpoint_name = \"tts-endpoint-async\"                          # Specify the SageMaker async endpoint to use\n",
    "retalking_endpoint_name = \"retalking-endpoint-async\"          # Specify the SageMaker async endpoint to use\n",
    "\n",
    "## Optional to change \n",
    "\n",
    "# Bucket params\n",
    "prefix_videos = \"videos\"                                      # Prefix to store the videos to be localized\n",
    "prefix_inputs = \"inputs\"                                      # Prefix to store the inference inputs for async call\n",
    "prefix_outputs = \"outputs\"                                    # Prefix to store the outputs for the inference\n",
    "prefix_voice_samples = \"voice-samples\"                        # Prefix to store the voice samples\n",
    "\n",
    "# Final output filenames\n",
    "final_output_audio_filename = inference_id + \".wav\"           # Final audio output\n",
    "final_output_video_filename = f\"{inference_id}-dubbed.mp4\"    # Final video output with retalking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def get_bucket(s3_uri):\n",
    "    bucket = s3_uri.split(\"/\")[2]\n",
    "    return bucket\n",
    "    \n",
    "def get_key(s3_uri):\n",
    "    key = \"/\".join(s3_uri.split(\"/\")[3:])\n",
    "    return key\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload file to S3 and Transcribe source file\n",
    "\n",
    "The following uploads the video to Amazon S3 and uses Amazon Transcribe to retrieve the transcription of the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload file\n",
    "key_video = prefix_videos + \"/\" + source_file.split(\"/\")[-1]\n",
    "\n",
    "s3 = boto3.client('s3', region_name=region_name)\n",
    "s3.upload_file(source_file, bucket, key_video)\n",
    "print(\"Uploaded file to s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start transcribe job for given object\n",
    "transcribe = boto3.client('transcribe', region_name=region_name)\n",
    "job_uri = \"s3://{}/{}\".format(bucket, key_video)\n",
    "job_timestamp = date.today().strftime(\"Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "job_name = key_video.split(\"/\")[-1].split(\".\")[0] + job_timestamp + \"-job\"\n",
    "\n",
    "result = transcribe.start_transcription_job(\n",
    "    TranscriptionJobName=job_name + \"1\",\n",
    "    Media={'MediaFileUri': job_uri},\n",
    "    MediaFormat=media_format,\n",
    "    LanguageCode=transcribe_source_language_code\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poll the transcriptionjobstatus until completed\n",
    "while True:\n",
    "    response = transcribe.get_transcription_job(TranscriptionJobName=job_name + \"1\")\n",
    "    job_status = response['TranscriptionJob']['TranscriptionJobStatus']\n",
    "    print(\"Transcription job status is:\", job_status)\n",
    "    if job_status == \"COMPLETED\":\n",
    "        # get the transcript from the transcribe job into a JSON\n",
    "        transcript_uri = response['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "        result = json.loads(requests.get(transcript_uri).content)\n",
    "        transcript = result['results']['transcripts'][0]['transcript']\n",
    "        print(\"Transcript:\")\n",
    "        print(transcript)\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate using Amazon Translate\n",
    "Using Amazon Translate, the transcript output of Amazon Transcribe is translated into the target language code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text by sentence to translate and recombine\n",
    "transcript_segments = transcript.split('.')\n",
    "\n",
    "# translate the transcript using Amazon Translate to spanish\n",
    "translate = boto3.client('translate', region_name=region_name)\n",
    "\n",
    "translated_segments = []\n",
    "for segment in transcript_segments:\n",
    "    if segment != '' and segment is not None:\n",
    "        \n",
    "        response = translate.translate_text(Text=segment + \".\",\n",
    "                                            SourceLanguageCode=translate_source_language_code,\n",
    "                                            TargetLanguageCode=translate_target_language_code)\n",
    "        translated_segments.append(response['TranslatedText'])\n",
    "        #print(f\"Original: {segment + '.'}\")\n",
    "        #print(f\"Translation: {response['TranslatedText']}\")\n",
    "        \n",
    "translated_text = ''.join(translated_segments)\n",
    "translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Reference Voice Clips\n",
    "The the following section performs the following:\n",
    "- Extracts the audio track from the source clip\n",
    "- Using the results from Amazon Transcribe, splits on sentences using the periods \".\"\n",
    "- Filters for voice samples that are greater than 2 seconds and less than 10 seconds needed for TortoiseTTS\n",
    "- Uploads the voice samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio from the source file\n",
    "source_audio = AudioSegment.from_file(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build splits\n",
    "sentences = []\n",
    "\n",
    "current_sentence = \"\"\n",
    "sentence_start_time = None\n",
    "sentence_end_time = None\n",
    "\n",
    "for item in result['results']['items']:\n",
    "    \n",
    "    # Punctuations don't have start and end_times\n",
    "    if item['type'] != 'punctuation':\n",
    "        \n",
    "        #Set the start_time if it's a new sentence\n",
    "        if sentence_start_time is None:\n",
    "            sentence_start_time = item['start_time']\n",
    "        \n",
    "        #Update the end time until the final word before a period    \n",
    "        sentence_end_time = item['end_time']\n",
    "        \n",
    "    # Concatenate the current word to the current sentence\n",
    "    \n",
    "    if item['type'] != 'punctuation':\n",
    "        current_sentence = current_sentence + ' ' + item['alternatives'][0]['content']\n",
    "    \n",
    "    if item['type'] == 'punctuation':\n",
    "        current_sentence = current_sentence + item['alternatives'][0]['content'] + ' '\n",
    "    \n",
    "    if item['type'] == 'punctuation' and item['alternatives'][0]['content'] == '.':        \n",
    "        sentences.append({\n",
    "            \"sentence\": current_sentence.strip(),\n",
    "            \"sentence_start_time\": float(sentence_start_time),\n",
    "            \"sentence_end_time\": float(sentence_end_time),\n",
    "            \"sentence_duration\": float(sentence_end_time) - float(sentence_start_time)\n",
    "        })\n",
    "        \n",
    "        current_sentence = \"\"\n",
    "        sentence_start_time = None\n",
    "        sentence_end_time = None\n",
    "        \n",
    "# Select segments that are >2 and <= 10 seconds in length\n",
    "selected_sentences = []\n",
    "for sentence in sentences:\n",
    "    if sentence['sentence_duration'] > 2 and sentence['sentence_duration'] <= 10:\n",
    "        selected_sentences.append(sentence)\n",
    "selected_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the voice_samples_dir if it doesn't exist\n",
    "if not os.path.exists(voice_samples_dir):\n",
    "    os.makedirs(voice_samples_dir)\n",
    "\n",
    "\n",
    "# Split and save audio\n",
    "i = 0\n",
    "for sentence in selected_sentences:\n",
    "    start_time_ms = sentence['sentence_start_time'] * 1000\n",
    "    end_time_ms = sentence['sentence_end_time'] * 1000\n",
    "    \n",
    "    segment = source_audio[start_time_ms:end_time_ms]\n",
    "    print(\"Exporting segment\", i, \"to\", f\"{voice_samples_dir}/{i}.wav\")\n",
    "    segment.export(f\"{voice_samples_dir}/{i}.wav\", format=\"wav\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload voice samples to Amazon S3\n",
    "for root, _, files in os.walk(voice_samples_dir):\n",
    "    for file in files:\n",
    "        full_path = os.path.join(root, file)\n",
    "        key =  prefix_voice_samples + \"/\" + s3_reference_voice_folder + \"/\" + file\n",
    "        print(f\"Uploading {full_path} to s3://{bucket}/{key}\")\n",
    "        s3.upload_file(full_path, bucket,key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform text-to-speech using SageMaker async endpoint\n",
    "The following section will do the following:\n",
    "- Given the translated transcript, split the text into sentences\n",
    "- Create multiple input requests JSON and uploads it to the input folder in the S3 bucket\n",
    "- Invoke the SageMaker using async invocation for all the input requests json\n",
    "\n",
    "\n",
    "__Taking advantage of parallel instances__ The sentences are split prior to doing multiple async invocations to parallelize the inference significantly reducing the time it takes to generate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "sagemaker = boto3.client('sagemaker-runtime', region_name=region_name)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Text\n",
    "\n",
    "Spliting the text is needed as there's limitations to how long the generation can be with the given models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text on periods \".\"\n",
    "def split_with_period(text):\n",
    "  \"\"\"Splits text on periods but keeps the period in the resulting list.\n",
    "\n",
    "  Args:\n",
    "      text: The text string to split.\n",
    "\n",
    "  Returns:\n",
    "      A list of substrings, including the periods.\n",
    "  \"\"\"\n",
    "  return re.split(r\"(?<=\\.)\\s\", text)\n",
    "\n",
    "translated_sentences = split_with_period(translated_text)\n",
    "translated_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare payloads\n",
    "'''\n",
    "The TTS SageMaker Endpoint accepts the following parameters:\n",
    "    id (int) The payload ID used for resequencing the files after generation\n",
    "    text (str) The text to be translated\n",
    "    voice_sampples_s3_uri (str) The S3 URI for the voice samples folder\n",
    "    input_s3_uri (str) The S3 URI for the payload\n",
    "    destination_s3_uri (str) The S3 URI for where the generated audio is uploaded to\n",
    "    model_id (str) Not currently used, Reserved for future use\n",
    "    inference_params (dict) Not currently used, reserved for future use\n",
    "'''\n",
    "\n",
    "payloads = []\n",
    "for translated_sentence,i in zip(translated_sentences, range(len(translated_sentences))):    \n",
    "    payload = {\"id\": i,\n",
    "               \"text\": translated_sentence, \n",
    "                \"voice_samples_s3_uri\": f\"s3://{bucket}/{prefix_voice_samples}/{s3_reference_voice_folder}\",\n",
    "                \"input_s3_uri\": f\"s3://{bucket}/{prefix_inputs}/{inference_id}/{inference_id}-part-{i}.json\",\n",
    "                \"destination_s3_uri\": f\"s3://{bucket}/{prefix_outputs}/{inference_id}/{i}.wav\", \n",
    "                \"model_id\": '',             # Not currently used, Reserved for future use\n",
    "                \"inference_params\": {}}     # Not currently used, Reserved for future use\n",
    "    payloads.append(payload)\n",
    "payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload payloads to Amazon S3\n",
    "\n",
    "s3 = boto3.resource('s3', region_name=region_name)\n",
    "sagemaker = boto3.client('sagemaker-runtime', region_name=region_name)\n",
    "\n",
    "for payload in payloads:\n",
    "    \n",
    "    # Upload the request json\n",
    "    print(f\"Uploading {payload['input_s3_uri']}\")\n",
    "    key = \"/\".join(payload['input_s3_uri'].split(\"/\")[3:])\n",
    "    s3_object = s3.Object(bucket, key)\n",
    "    s3_object.put(Body=json.dumps(payload).encode('utf-8'))\n",
    "\n",
    "    # Invoke SageMaker async endpoint\n",
    "    print(f\"Invoking {endpoint_name} with {payload['input_s3_uri']}\")\n",
    "    response = sagemaker.invoke_endpoint_async(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/json',\n",
    "        InputLocation=payload['input_s3_uri'],\n",
    "        InvocationTimeoutSeconds=3600\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poll for completion\n",
    "s3 = boto3.client('s3', region_name=region_name)\n",
    "\n",
    "all_completed = False  # Flag to track completion\n",
    "\n",
    "while not all_completed:\n",
    "    print(\"=================\")\n",
    "    print(f\"Checking progress - {datetime.now()}\")\n",
    "    completed_count = 0  # Count completed payloads\n",
    "\n",
    "    for payload in payloads:\n",
    "        key = \"/\".join(payload['destination_s3_uri'].split(\"/\")[3:])\n",
    "        print(f\"{payload['id']}...\", end=\"\")\n",
    "        try:\n",
    "            s3.head_object(Bucket=bucket, Key=key)\n",
    "            print(\" Completed.\")\n",
    "            completed_count += 1\n",
    "        except:\n",
    "            print(\" In Progress.\")\n",
    "\n",
    "    # Check if all payloads are completed\n",
    "    all_completed = completed_count == len(payloads)\n",
    "\n",
    "    if all_completed:\n",
    "        print(\"All payloads completed!\")\n",
    "    else:\n",
    "        sleep(10)\n",
    "        clear_output(wait=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3', region_name=region_name)\n",
    "\n",
    "# Create a temporary directory to download the parts to\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    \n",
    "    final_output_audio = AudioSegment.empty()\n",
    "    \n",
    "    for payload in payloads:\n",
    "        print(f\"Downloading {payload['destination_s3_uri']}\")\n",
    "        bucket = get_bucket(payload['destination_s3_uri'])\n",
    "        key = get_key(payload['destination_s3_uri'])\n",
    "        \n",
    "        local_filepath = os.path.join(tmpdir, key.split(\"/\")[-1])\n",
    "        s3.download_file(bucket, key, local_filepath)\n",
    "        \n",
    "        \n",
    "        # concatenate files\n",
    "        final_output_audio += AudioSegment.from_wav(local_filepath)\n",
    "        \n",
    "    print(f\"Creating final audio {final_output_audio_filename}\")\n",
    "    final_output_audio.export(final_output_audio_filename, format=\"wav\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take source video and source audio lengths, calculate tempo to adjust audio speed\n",
    "import subprocess\n",
    "\n",
    "\n",
    "final_output_audio_atempo_filename = f\"{inference_id}-atempo.wav\"\n",
    "\n",
    "# Retrieve lengths\n",
    "source_length = len(source_audio)\n",
    "dubbed_audio = AudioSegment.from_file(final_output_audio_filename)\n",
    "dubbed_length = len(dubbed_audio)\n",
    "\n",
    "# Calculate atempo adjustment\n",
    "atempo = dubbed_length/source_length\n",
    "\n",
    "# Adjust final audio\n",
    "subprocess.run([\n",
    "    'ffmpeg', '-i', final_output_audio_filename, '-filter:a', f'atempo={atempo}', '-y', final_output_audio_atempo_filename\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the final audio\n",
    "key = f\"{prefix_outputs}/{final_output_audio_atempo_filename}\"\n",
    "s3.upload_file(final_output_audio_atempo_filename, bucket, key)\n",
    "print(f\"Uploaded final tempo adjusted file - s3://{bucket}/{key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform video retalking using SageMaker async endpoint \n",
    "```\n",
    "The SageMaker Retalking Endpoint accepts the following parameters:\n",
    "    input_s3_uri (str): The S3 URI of the payload file\n",
    "    input_video_s3_uri (str): The S3 URI of the input video\n",
    "    input_audio_s3_uri (str): The S3 URI of the input audio to lip sync with\n",
    "    output_video_s3_uri (str): The S3 URI of where the new video will be outputted to\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prepare payload\n",
    "s3 = boto3.resource('s3', region_name=region_name)\n",
    "sagemaker = boto3.client('sagemaker-runtime', region_name=region_name)\n",
    "\n",
    "payload = {\n",
    "        \"input_s3_uri\": f\"s3://{bucket}/{prefix_inputs}/{inference_id}.json\",\n",
    "        \"input_video_s3_uri\": f\"s3://{bucket}/{prefix_videos}/{os.path.basename(source_file)}\",\n",
    "        \"input_audio_s3_uri\": f\"s3://{bucket}/{prefix_outputs}/{final_output_audio_atempo_filename}\",\n",
    "        \"output_video_s3_uri\": f\"s3://{bucket}/{prefix_outputs}/{final_output_video_filename}\",\n",
    "        \"inference_params\": {},\n",
    "    }\n",
    "\n",
    "    \n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the request json\n",
    "print(f\"Uploading {payload['input_s3_uri']}\")\n",
    "key = \"/\".join(payload['input_s3_uri'].split(\"/\")[3:])\n",
    "s3_object = s3.Object(bucket, key)\n",
    "s3_object.put(Body=json.dumps(payload).encode('utf-8'))\n",
    "\n",
    "# Invoke SageMaker async endpoint\n",
    "print(f\"Invoking {retalking_endpoint_name} with {payload['input_s3_uri']}\")\n",
    "response = sagemaker.invoke_endpoint_async(\n",
    "    EndpointName=retalking_endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    InputLocation=payload['input_s3_uri'],\n",
    "    InvocationTimeoutSeconds=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poll for completion\n",
    "s3 = boto3.client('s3', region_name=region_name)\n",
    "\n",
    "all_completed = False  # Flag to track completion\n",
    "\n",
    "while not all_completed:\n",
    "    print(\"=================\")\n",
    "    print(f\"Checking progress - {datetime.now()}\")\n",
    "    completed_count = 0  # Count completed payloads\n",
    "\n",
    "    key = \"/\".join(payload['output_video_s3_uri'].split(\"/\")[3:])\n",
    "    try:\n",
    "        s3.head_object(Bucket=bucket, Key=key)\n",
    "        print(\" Completed.\")\n",
    "        all_completed = True\n",
    "    except:\n",
    "        print(\" In Progress.\")\n",
    "\n",
    "    if all_completed:\n",
    "        print(\"Retalking completed!\")\n",
    "    else:\n",
    "        sleep(10)\n",
    "        clear_output(wait=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the completed file\n",
    "\n",
    "s3.download_file(bucket, key, final_output_video_filename)\n",
    "print(f\"Downloaded to {final_output_video_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "localization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
